import { GoogleGenAI, Modality, GenerateContentResponse, Part } from "@google/genai";
import { ImageFile, AspectRatio } from '../types';

// FIX: Removed conflicting global declaration for window.aistudio.
// This resolves errors indicating a duplicate or incompatible declaration,
// as the 'aistudio' object is expected to be available globally in the execution environment.

export const fileToBase64 = (file: File): Promise<string> => {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsDataURL(file);
    reader.onload = () => resolve((reader.result as string).split(',')[1]);
    reader.onerror = (error) => reject(error);
  });
};

// Prompt Enhancement
export const enhancePrompt = async (idea: string): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
  const response = await ai.models.generateContent({
    model: 'gemini-2.5-pro',
    contents: idea,
    config: {
        systemInstruction: `You are an AI assistant specializing in prompt engineering for text-to-image models like Imagen. 
Your task is to take a user's simple idea and expand it into a detailed, professional, and highly effective prompt. 
The prompt should include details about subject, style (e.g., photorealistic, watercolor, cyberpunk), composition, lighting, and mood to generate a high-quality, visually stunning image. 
Respond ONLY with the generated prompt text, without any introductory phrases like "Here is the prompt:" or any other conversational text. Just the prompt itself.`
    }
  });
  return response.text.trim();
};

// Text-to-Image Generation
export const generateImage = async (prompt: string): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
  const response = await ai.models.generateImages({
    model: 'imagen-4.0-generate-001',
    prompt,
    config: {
      numberOfImages: 1,
      outputMimeType: 'image/jpeg',
      aspectRatio: '1:1',
    },
  });

  const base64ImageBytes = response.generatedImages[0].image.imageBytes;
  return `data:image/jpeg;base64,${base64ImageBytes}`;
};

// Image Editing with Text
export const editImage = async (prompt: string, image: ImageFile): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [
        { inlineData: { data: image.base64, mimeType: image.mimeType } },
        { text: prompt },
      ],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }
  throw new Error('No image generated by the model.');
};

// Style Transfer
export const transferStyle = async (contentImage: ImageFile, styleImage: ImageFile): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
  const prompt = `Analyze the artistic style, color palette, and texture from the second image (the style image) and apply it to the first image (the content image). The composition and subject matter of the content image should be preserved. Generate a new image that is a fusion of the content from the first image and the style of the second.`;

  const parts: Part[] = [
    { text: prompt },
    { inlineData: { data: contentImage.base64, mimeType: contentImage.mimeType } },
    { inlineData: { data: styleImage.base64, mimeType: styleImage.mimeType } },
  ];

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: { parts },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }
  throw new Error('No image generated by the model.');
};

// Multi-image "Outfit Studio" generation
export const createOutfit = async (prompt: string, personImage: ImageFile, clothingImages: ImageFile[]): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
  const parts: Part[] = [
    { text: prompt },
    { text: "This is the person to dress:" },
    { inlineData: { data: personImage.base64, mimeType: personImage.mimeType } },
    { text: "Use these clothing items:" },
    ...clothingImages.map(img => ({
      inlineData: { data: img.base64, mimeType: img.mimeType }
    })),
  ];

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: { parts },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }
  throw new Error('No image generated by the model.');
};


// Video Generation
export const generateVideo = async (
  prompt: string,
  image: ImageFile,
  aspectRatio: AspectRatio,
  onProgress: (message: string) => void
): Promise<string> => {
    // A new instance must be created right before the API call.
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
    
    onProgress('Initiating video generation...');
    let operation = await ai.models.generateVideos({
      model: 'veo-3.1-fast-generate-preview',
      prompt,
      image: {
        imageBytes: image.base64,
        mimeType: image.mimeType,
      },
      config: {
        numberOfVideos: 1,
        resolution: '720p',
        aspectRatio: aspectRatio,
      }
    });

    const progressMessages = [
      "Warming up the digital loom...",
      "Weaving pixels into motion...",
      "Rendering the first sequence...",
      "Almost there, adding finishing touches...",
      "Finalizing the masterpiece...",
    ];
    let messageIndex = 0;

    while (!operation.done) {
        onProgress(progressMessages[messageIndex % progressMessages.length]);
        messageIndex++;
        await new Promise(resolve => setTimeout(resolve, 10000));
        operation = await ai.operations.getVideosOperation({operation: operation});
    }

    onProgress('Fetching your video...');
    const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (!downloadLink) {
        throw new Error('Video generation completed but no download link was found.');
    }

    const response = await fetch(`${downloadLink}&key=${process.env.API_KEY}`);
    if (!response.ok) {
        throw new Error(`Failed to download video: ${response.statusText}`);
    }
    const videoBlob = await response.blob();
    return URL.createObjectURL(videoBlob);
};